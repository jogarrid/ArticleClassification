{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import mpl_toolkits.mplot3d as mplt3d\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "\n",
    "%matplotlib notebook\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# shouldn't be enabled when using interactive 3D plots\n",
    "# %pylab inline\n",
    "# pylab.rcParams['figure.figsize'] = (10, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning & preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naming chosen for same-length, to look pretty\n",
    "kicked = pd.read_csv('../data/DISMISSED_final.csv')\n",
    "stayed = pd.read_csv('../data/UNDISMISSED_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Query</th>\n",
       "      <th>Authors</th>\n",
       "      <th>organisation</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>co-authors</th>\n",
       "      <th>headings</th>\n",
       "      <th>keywords</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AU=SARAC CEMAL</td>\n",
       "      <td>SARAC CEMAL</td>\n",
       "      <td>MARMARA UNIV</td>\n",
       "      <td>In this study, it was aimed to determine the v...</td>\n",
       "      <td>SARAC CEMAL</td>\n",
       "      <td>['SARAC CEMAL']</td>\n",
       "      <td>['Social Sciences']</td>\n",
       "      <td>['Turkish Language and Literature Teacher Trai...</td>\n",
       "      <td>2011-06-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>KURAM VE UYGULAMADA EGITIM BILIMLERI</td>\n",
       "      <td>A Proposal of \"Applied Social Activities\" Modu...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>939</td>\n",
       "      <td>AU=KOSE IBRAHIM</td>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>ADIYAMAN UNIV</td>\n",
       "      <td>We assessed the benefit of bone morphogenic pr...</td>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>['KOPARAL MAHMUT', 'KOSE IBRAHIM', 'ATALAY YUS...</td>\n",
       "      <td>['Science &amp; Technology']</td>\n",
       "      <td>['Bone healing', 'experimental surgery', 'low-...</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>INTERNATIONAL JOURNAL OF CLINICAL AND EXPERIME...</td>\n",
       "      <td>The effects of recombinant human bone morphoge...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>940</td>\n",
       "      <td>AU=KOSE IBRAHIM</td>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>ADIYAMAN UNIV</td>\n",
       "      <td>This study was supported by the Scientific Res...</td>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>['ATALAY YUSUF', 'BOZKURT MEHMET FATIH', 'GONU...</td>\n",
       "      <td>['Science &amp; Technology']</td>\n",
       "      <td>['amlodipine', 'calcium channel blockers', 'pl...</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>DRUG DESIGN DEVELOPMENT AND THERAPY</td>\n",
       "      <td>The effects of amlodipine and platelet rich pl...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1            Query       Authors   organisation  \\\n",
       "0           0             0   AU=SARAC CEMAL   SARAC CEMAL   MARMARA UNIV   \n",
       "1           1           939  AU=KOSE IBRAHIM  KOSE IBRAHIM  ADIYAMAN UNIV   \n",
       "2           2           940  AU=KOSE IBRAHIM  KOSE IBRAHIM  ADIYAMAN UNIV   \n",
       "\n",
       "                                            abstract        author  \\\n",
       "0  In this study, it was aimed to determine the v...   SARAC CEMAL   \n",
       "1  We assessed the benefit of bone morphogenic pr...  KOSE IBRAHIM   \n",
       "2  This study was supported by the Scientific Res...  KOSE IBRAHIM   \n",
       "\n",
       "                                          co-authors  \\\n",
       "0                                    ['SARAC CEMAL']   \n",
       "1  ['KOPARAL MAHMUT', 'KOSE IBRAHIM', 'ATALAY YUS...   \n",
       "2  ['ATALAY YUSUF', 'BOZKURT MEHMET FATIH', 'GONU...   \n",
       "\n",
       "                   headings  \\\n",
       "0       ['Social Sciences']   \n",
       "1  ['Science & Technology']   \n",
       "2  ['Science & Technology']   \n",
       "\n",
       "                                            keywords publish_date  pubtype  \\\n",
       "0  ['Turkish Language and Literature Teacher Trai...   2011-06-01  Journal   \n",
       "1  ['Bone healing', 'experimental surgery', 'low-...   2016-01-01  Journal   \n",
       "2  ['amlodipine', 'calcium channel blockers', 'pl...   2015-01-01  Journal   \n",
       "\n",
       "                                              source  \\\n",
       "0               KURAM VE UYGULAMADA EGITIM BILIMLERI   \n",
       "1  INTERNATIONAL JOURNAL OF CLINICAL AND EXPERIME...   \n",
       "2                DRUG DESIGN DEVELOPMENT AND THERAPY   \n",
       "\n",
       "                                               title  labels  \n",
       "0  A Proposal of \"Applied Social Activities\" Modu...     1.0  \n",
       "1  The effects of recombinant human bone morphoge...     1.0  \n",
       "2  The effects of amlodipine and platelet rich pl...     1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kicked.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>abstract</th>\n",
       "      <th>author</th>\n",
       "      <th>co-authors</th>\n",
       "      <th>headings</th>\n",
       "      <th>keywords</th>\n",
       "      <th>organisation</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>pubtype</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Previous studies have reported a relationship ...</td>\n",
       "      <td>'ISINGOR MELEK'</td>\n",
       "      <td>['KURT ERHAN', 'GULER OZKAN', 'OZBULUT OMER', ...</td>\n",
       "      <td>['Social Sciences', 'Science &amp; Technology']</td>\n",
       "      <td>['suicide', 'ghrelin', 'leptin', 'cholesterol'...</td>\n",
       "      <td>['BAKIRKOY RES &amp; TRAINING HOSP PSYCHIAT &amp; NEUR...</td>\n",
       "      <td>2008-01-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>JOURNAL OF PSYCHOPHYSIOLOGY</td>\n",
       "      <td>Evaluation of Serum Ghrelin and Leptin Levels ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>'YILMAZ MESUT'</td>\n",
       "      <td>['OZARAS RESAT', 'YILMAZ MESUT', 'METE BIRGUL'...</td>\n",
       "      <td>['Science &amp; Technology']</td>\n",
       "      <td>['INFECTION', 'ALT']</td>\n",
       "      <td>['CERRAHPASA MED FAC UNIV ISTANBUL AKSARAY', '...</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>DIGESTIVE DISEASES AND SCIENCES</td>\n",
       "      <td>Recognizing Acute Hepatitis C in Hemodialysis ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pseudomonas menclocina, a Gram-negative non-fe...</td>\n",
       "      <td>'YILMAZ MESUT'</td>\n",
       "      <td>['MERT ALI', 'YILMAZ MESUT', 'OZARAS RESAT', '...</td>\n",
       "      <td>['Science &amp; Technology']</td>\n",
       "      <td>['INFECTIVE ENDOCARDITIS']</td>\n",
       "      <td>['UNIV ISTANBUL', 'SIYAMI ERSEK THORAC &amp; CARDI...</td>\n",
       "      <td>2007-01-01</td>\n",
       "      <td>Journal</td>\n",
       "      <td>SCANDINAVIAN JOURNAL OF INFECTIOUS DISEASES</td>\n",
       "      <td>Native valve endocarditis due to Pseudomonas m...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           abstract  \\\n",
       "0           0  Previous studies have reported a relationship ...   \n",
       "1           1                                                NaN   \n",
       "2           2  Pseudomonas menclocina, a Gram-negative non-fe...   \n",
       "\n",
       "             author                                         co-authors  \\\n",
       "0   'ISINGOR MELEK'  ['KURT ERHAN', 'GULER OZKAN', 'OZBULUT OMER', ...   \n",
       "1    'YILMAZ MESUT'  ['OZARAS RESAT', 'YILMAZ MESUT', 'METE BIRGUL'...   \n",
       "2    'YILMAZ MESUT'  ['MERT ALI', 'YILMAZ MESUT', 'OZARAS RESAT', '...   \n",
       "\n",
       "                                      headings  \\\n",
       "0  ['Social Sciences', 'Science & Technology']   \n",
       "1                     ['Science & Technology']   \n",
       "2                     ['Science & Technology']   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  ['suicide', 'ghrelin', 'leptin', 'cholesterol'...   \n",
       "1                               ['INFECTION', 'ALT']   \n",
       "2                         ['INFECTIVE ENDOCARDITIS']   \n",
       "\n",
       "                                        organisation publish_date  pubtype  \\\n",
       "0  ['BAKIRKOY RES & TRAINING HOSP PSYCHIAT & NEUR...   2008-01-01  Journal   \n",
       "1  ['CERRAHPASA MED FAC UNIV ISTANBUL AKSARAY', '...   2008-12-01  Journal   \n",
       "2  ['UNIV ISTANBUL', 'SIYAMI ERSEK THORAC & CARDI...   2007-01-01  Journal   \n",
       "\n",
       "                                        source  \\\n",
       "0                  JOURNAL OF PSYCHOPHYSIOLOGY   \n",
       "1              DIGESTIVE DISEASES AND SCIENCES   \n",
       "2  SCANDINAVIAN JOURNAL OF INFECTIOUS DISEASES   \n",
       "\n",
       "                                               title  labels  \n",
       "0  Evaluation of Serum Ghrelin and Leptin Levels ...     0.0  \n",
       "1  Recognizing Acute Hepatitis C in Hemodialysis ...     0.0  \n",
       "2  Native valve endocarditis due to Pseudomonas m...     0.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stayed.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28830, 15), (79979, 12))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kicked.shape, stayed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28830, 3), (28830, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kicked1 = kicked[['author','title', 'labels']]\n",
    "stayed1 = stayed[['author','title', 'labels']]\n",
    "\n",
    "stayed1 = stayed1.sample(frac=(1.0 * kicked.shape[0])/stayed.shape[0]) # random_state = 0\n",
    "\n",
    "# made arrays equal in size\n",
    "kicked1.shape, stayed1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# check some basic invariants on the input data, all should return True\n",
    "print(kicked1['labels'].apply(lambda x: x == 1).all())\n",
    "print(stayed1['labels'].apply(lambda x: x == 0).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SARAC CEMAL</td>\n",
       "      <td>a proposal applied social activities module fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>the effects recombinant human bone morphogenic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KOSE IBRAHIM</td>\n",
       "      <td>the effects amlodipine and platelet rich plasm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MALKOC SIDDIK</td>\n",
       "      <td>a patient and family centered care approach or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MALKOC SIDDIK</td>\n",
       "      <td>treatment post orthodontic white spot lesions ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          author                                              title  labels\n",
       "0    SARAC CEMAL  a proposal applied social activities module fo...       1\n",
       "1   KOSE IBRAHIM  the effects recombinant human bone morphogenic...       1\n",
       "2   KOSE IBRAHIM  the effects amlodipine and platelet rich plasm...       1\n",
       "3  MALKOC SIDDIK  a patient and family centered care approach or...       1\n",
       "4  MALKOC SIDDIK  treatment post orthodontic white spot lesions ...       1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df0 = pd.concat([kicked1, stayed1])\n",
    "df0['labels'] = df0['labels'].apply(lambda x: int(x))\n",
    "\n",
    "df1 = get_cleaned_dataset(df0)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (title, label) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a proposal applied social activities module fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the effects recombinant human bone morphogenic...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the effects amlodipine and platelet rich plasm...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a patient and family centered care approach or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>treatment post orthodontic white spot lesions ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  labels\n",
       "0  a proposal applied social activities module fo...       1\n",
       "1  the effects recombinant human bone morphogenic...       1\n",
       "2  the effects amlodipine and platelet rich plasm...       1\n",
       "3  a patient and family centered care approach or...       1\n",
       "4  treatment post orthodontic white spot lesions ...       1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = get_title_label_dataset(df1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get (concatenated-titles-per-author, label) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the interesting observation is that now we have a dataset of (title, label), where label is\n",
    "# if the author of the article was fired or not. Such dataset may be biased, because for one author\n",
    "# there can be a lot of different articles. Thus many points are produced with single observation\n",
    "\n",
    "# Let's try also with another dataset, where we will also have (conc_title, label), where conc_title\n",
    "# will stay for all the titles of one author, being concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For first dataset we have 57629 titles, from them 28830 kicked and 28799 stayed\n"
     ]
    }
   ],
   "source": [
    "titles_num = df2.shape[0]\n",
    "kicked_titles_num = df2[df2['labels'] == 1].shape[0]\n",
    "stayed_titles_num = df2[df2['labels'] == 0].shape[0]\n",
    "print('For first dataset we have ' + str(titles_num) + ' titles, from them ' + str(kicked_titles_num) + ' kicked and ' + str(stayed_titles_num) + ' stayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After aggregation we got 4784 authors, from which 2083 were kicked and 2701 not\n",
      "Taking prefix of required size for not-kicked\n",
      "Got aggregated dataset of size 4166\n",
      "New dataset size after duplicates removal is 4139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>investigating aluminum sheet wrinkling during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sulcal and gyral anatomy the orbitofrontal co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a non contact method for part based process p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cement thickness inlay restorations made lith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>chemical composition and biological activity ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              title\n",
       "0       0   investigating aluminum sheet wrinkling during...\n",
       "1       0   sulcal and gyral anatomy the orbitofrontal co...\n",
       "2       0   a non contact method for part based process p...\n",
       "3       1   cement thickness inlay restorations made lith...\n",
       "4       0   chemical composition and biological activity ..."
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adf = aggregated data frame\n",
    "adf2 = get_cleaned_concatenated_titles_label_dataset(df1)\n",
    "adf2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# important! Now all classification can be made on one of two dataframes, choice is made here!\n",
    "if True:\n",
    "    df = adf2\n",
    "else:\n",
    "    df = df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2897,), (1242,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.3) # random_state = 0\n",
    "\n",
    "X_train = data_train['title']\n",
    "y_train = data_train['labels']\n",
    "\n",
    "X_test = data_test['title']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do the following model\n",
    "# Features are unique words\n",
    "# Samples are titles\n",
    "\n",
    "# 1) Naive : for every sample we have binary value for every word (present / absent)\n",
    "# 2) sklearn.CountVectorizer : counting\n",
    "# 3) sklearn.TfidfVectorizer : with usual counting more weight is given to longer sentences, that's not really\n",
    "#                               fair, TF-IDF (term frequency _times_ inverse document frequency) also gives\n",
    "#                               every sample a weight for each present word, but in more sophisticated way\n",
    "\n",
    "# We are doing (3) classificator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape:  (2897, 26798)\n",
      "Test  shape:  (1242, 26798)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "print('Train shape: ', X_train_tfidf.shape)\n",
    "\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "print('Test  shape: ', X_test_tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5933977455716586"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(clf.predict(X_test_tfidf) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec experiments + catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, we had a look at NB combined with TF-IDF\n",
    "# Let's now work with word2vec. We need to handle sentences, thus we have 2 options:\n",
    "# 1) Do simple averaging of all the words in sentence\n",
    "# 2) Do TF-IDF weighting of every word in a sentence and then addition\n",
    "# Then for classification we use catboost (ie gradient boosting ie combination of decision trees)\n",
    "\n",
    "# We will try both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pretrained model\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../data/pretrained_models/GoogleNews-vectors-negative300.bin.gz', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 2897 vs test size: 1242\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.3) # random_state = 0\n",
    "\n",
    "X_train = data_train['title']\n",
    "y_train = data_train['labels']\n",
    "\n",
    "X_test = data_test['title']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "print('Train size: ' + str(X_train.shape[0]) + ' vs test size: ' + str(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>investigating aluminum sheet wrinkling during...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>sulcal and gyral anatomy the orbitofrontal co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>a non contact method for part based process p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>cement thickness inlay restorations made lith...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>chemical composition and biological activity ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>effect nacl salt the permeability base clay l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>correlates clozapine use after first episode ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>investigation the effects alpha lipoic acid a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>an unexpected long term complication genital ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>urolithiasis infants evaluation risk factors ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labels                                              title\n",
       "0       0   investigating aluminum sheet wrinkling during...\n",
       "1       0   sulcal and gyral anatomy the orbitofrontal co...\n",
       "2       0   a non contact method for part based process p...\n",
       "3       1   cement thickness inlay restorations made lith...\n",
       "4       0   chemical composition and biological activity ...\n",
       "5       1   effect nacl salt the permeability base clay l...\n",
       "6       0   correlates clozapine use after first episode ...\n",
       "7       0   investigation the effects alpha lipoic acid a...\n",
       "8       0   an unexpected long term complication genital ...\n",
       "9       0   urolithiasis infants evaluation risk factors ..."
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_w2v_embeddings(titles):\n",
    "    embs = []\n",
    "    for title in titles:\n",
    "        title_emb = np.zeros(300)\n",
    "        words = title.split(' ')\n",
    "        for w in words:\n",
    "            if w in word2vec_model:\n",
    "                scalar = 1.\n",
    "#                 scalar = 1. / len(words)\n",
    "                \n",
    "                vector = word2vec_model[w]\n",
    "                \n",
    "                title_emb += scalar * vector\n",
    "        embs.append(title_emb)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Series is provided, indexation is made with iloc\n",
    "def get_tfidf_w2v_embeddings(titles):\n",
    "    tfidf_vect = TfidfVectorizer()\n",
    "    \n",
    "    titles_tfidf_matrix = tfidf_vect.fit_transform(titles)\n",
    "    # have matrix, where rows are titles and cols are words from vocabulary\n",
    "    tfidf_words_indices = {word : index for (word, index) in tfidf_vect.vocabulary_.items()}\n",
    "    \n",
    "    embs = []\n",
    "    for i in range(len(titles)):\n",
    "        title = titles.iloc[i]\n",
    "        words = title.split(' ')\n",
    "        \n",
    "        # make sparse matrix row a dict:\n",
    "        matrix_row = titles_tfidf_matrix[i]\n",
    "        matrix_row_dict = {}\n",
    "        indices = matrix_row.indices\n",
    "        data    = matrix_row.data\n",
    "        for i in range(len(data)):\n",
    "            matrix_row_dict[indices[i]] = data[i]\n",
    "        \n",
    "        title_emb = np.zeros(300)\n",
    "        for w in words:\n",
    "            if w in word2vec_model:\n",
    "                vector = word2vec_model[w]\n",
    "                \n",
    "                if w in tfidf_words_indices:\n",
    "                    word_index = tfidf_words_indices[w]\n",
    "                    scalar = matrix_row_dict.get(word_index, 0)\n",
    "                else:\n",
    "                    scalar = 1. / len(words) # take scalar as in mean\n",
    "#                     scalar = 1.\n",
    "                \n",
    "                title_emb += scalar * vector\n",
    "                \n",
    "        embs.append(title_emb)\n",
    "    return embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    X_train_embs = get_mean_w2v_embeddings(X_train)\n",
    "    X_test_embs  = get_mean_w2v_embeddings(X_test)\n",
    "else:\n",
    "    X_train_embs = get_tfidf_w2v_embeddings(X_train)\n",
    "    X_test_embs  = get_tfidf_w2v_embeddings(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6918035\ttotal: 174ms\tremaining: 3.3s\n",
      "1:\tlearn: 0.6903760\ttotal: 345ms\tremaining: 3.1s\n",
      "2:\tlearn: 0.6891240\ttotal: 575ms\tremaining: 3.26s\n",
      "3:\tlearn: 0.6878366\ttotal: 821ms\tremaining: 3.28s\n",
      "4:\tlearn: 0.6868379\ttotal: 1.02s\tremaining: 3.07s\n",
      "5:\tlearn: 0.6855826\ttotal: 1.24s\tremaining: 2.89s\n",
      "6:\tlearn: 0.6844164\ttotal: 1.46s\tremaining: 2.71s\n",
      "7:\tlearn: 0.6830770\ttotal: 1.65s\tremaining: 2.48s\n",
      "8:\tlearn: 0.6818916\ttotal: 1.84s\tremaining: 2.24s\n",
      "9:\tlearn: 0.6807051\ttotal: 2s\tremaining: 2s\n",
      "10:\tlearn: 0.6797081\ttotal: 2.2s\tremaining: 1.8s\n",
      "11:\tlearn: 0.6788609\ttotal: 2.43s\tremaining: 1.62s\n",
      "12:\tlearn: 0.6777693\ttotal: 2.61s\tremaining: 1.41s\n",
      "13:\tlearn: 0.6765518\ttotal: 2.78s\tremaining: 1.19s\n",
      "14:\tlearn: 0.6757515\ttotal: 2.98s\tremaining: 994ms\n",
      "15:\tlearn: 0.6747088\ttotal: 3.21s\tremaining: 803ms\n",
      "16:\tlearn: 0.6736187\ttotal: 3.42s\tremaining: 604ms\n",
      "17:\tlearn: 0.6726837\ttotal: 3.63s\tremaining: 403ms\n",
      "18:\tlearn: 0.6715939\ttotal: 3.84s\tremaining: 202ms\n",
      "19:\tlearn: 0.6706568\ttotal: 4.03s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6497584541062802"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "cbc_model = CatBoostClassifier(iterations=20, learning_rate=0.01, depth=6, loss_function='Logloss')\n",
    "cbc_model.fit(X_train_embs, y_train)\n",
    "preds_class = cbc_model.predict(X_test_embs)\n",
    "\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6803691\ttotal: 164ms\tremaining: 3.12s\n",
      "1:\tlearn: 0.6711555\ttotal: 330ms\tremaining: 2.97s\n",
      "2:\tlearn: 0.6636811\ttotal: 536ms\tremaining: 3.04s\n",
      "3:\tlearn: 0.6556796\ttotal: 742ms\tremaining: 2.97s\n",
      "4:\tlearn: 0.6475585\ttotal: 917ms\tremaining: 2.75s\n",
      "5:\tlearn: 0.6395406\ttotal: 1.1s\tremaining: 2.58s\n",
      "6:\tlearn: 0.6324571\ttotal: 1.28s\tremaining: 2.38s\n",
      "7:\tlearn: 0.6279194\ttotal: 1.46s\tremaining: 2.19s\n",
      "8:\tlearn: 0.6224003\ttotal: 1.63s\tremaining: 1.99s\n",
      "9:\tlearn: 0.6171276\ttotal: 1.83s\tremaining: 1.83s\n",
      "10:\tlearn: 0.6131675\ttotal: 2.02s\tremaining: 1.65s\n",
      "11:\tlearn: 0.6097541\ttotal: 2.19s\tremaining: 1.46s\n",
      "12:\tlearn: 0.6052413\ttotal: 2.37s\tremaining: 1.28s\n",
      "13:\tlearn: 0.6017060\ttotal: 2.55s\tremaining: 1.09s\n",
      "14:\tlearn: 0.5977467\ttotal: 2.71s\tremaining: 902ms\n",
      "15:\tlearn: 0.5940677\ttotal: 2.88s\tremaining: 719ms\n",
      "16:\tlearn: 0.5916500\ttotal: 3.04s\tremaining: 536ms\n",
      "17:\tlearn: 0.5895611\ttotal: 3.22s\tremaining: 357ms\n",
      "18:\tlearn: 0.5875943\ttotal: 3.38s\tremaining: 178ms\n",
      "19:\tlearn: 0.5842895\ttotal: 3.55s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6578099838969405"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_model = CatBoostClassifier(iterations=20, learning_rate=0.1, depth=6, loss_function='Logloss')\n",
    "cbc_model.fit(X_train_embs, y_train)\n",
    "preds_class = cbc_model.predict(X_test_embs)\n",
    "\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6278073\ttotal: 181ms\tremaining: 3.43s\n",
      "1:\tlearn: 0.6123651\ttotal: 351ms\tremaining: 3.16s\n",
      "2:\tlearn: 0.5951767\ttotal: 534ms\tremaining: 3.03s\n",
      "3:\tlearn: 0.5836713\ttotal: 741ms\tremaining: 2.96s\n",
      "4:\tlearn: 0.5712709\ttotal: 936ms\tremaining: 2.81s\n",
      "5:\tlearn: 0.5658822\ttotal: 1.14s\tremaining: 2.66s\n",
      "6:\tlearn: 0.5465612\ttotal: 1.37s\tremaining: 2.55s\n",
      "7:\tlearn: 0.5387028\ttotal: 1.58s\tremaining: 2.36s\n",
      "8:\tlearn: 0.5354754\ttotal: 1.83s\tremaining: 2.23s\n",
      "9:\tlearn: 0.5219828\ttotal: 2.03s\tremaining: 2.03s\n",
      "10:\tlearn: 0.5071981\ttotal: 2.21s\tremaining: 1.81s\n",
      "11:\tlearn: 0.5051707\ttotal: 2.38s\tremaining: 1.59s\n",
      "12:\tlearn: 0.4917885\ttotal: 2.56s\tremaining: 1.38s\n",
      "13:\tlearn: 0.4808361\ttotal: 2.77s\tremaining: 1.19s\n",
      "14:\tlearn: 0.4734535\ttotal: 2.93s\tremaining: 978ms\n",
      "15:\tlearn: 0.4650555\ttotal: 3.1s\tremaining: 776ms\n",
      "16:\tlearn: 0.4639828\ttotal: 3.26s\tremaining: 575ms\n",
      "17:\tlearn: 0.4574351\ttotal: 3.44s\tremaining: 382ms\n",
      "18:\tlearn: 0.4489720\ttotal: 3.61s\tremaining: 190ms\n",
      "19:\tlearn: 0.4412223\ttotal: 3.77s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6159420289855072"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_model = CatBoostClassifier(iterations=20, learning_rate=1, depth=6, loss_function='Logloss')\n",
    "cbc_model.fit(X_train_embs, y_train)\n",
    "preds_class = cbc_model.predict(X_test_embs)\n",
    "\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.9837736\ttotal: 189ms\tremaining: 3.58s\n",
      "1:\tlearn: 65.1416292\ttotal: 352ms\tremaining: 3.17s\n",
      "2:\tlearn: 525.7721073\ttotal: 541ms\tremaining: 3.06s\n",
      "3:\tlearn: nan\ttotal: 551ms\tremaining: 2.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 3, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5249597423510467"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbc_model = CatBoostClassifier(iterations=20, learning_rate=10, depth=6, loss_function='Logloss')\n",
    "cbc_model.fit(X_train_embs, y_train)\n",
    "preds_class = cbc_model.predict(X_test_embs)\n",
    "\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sent2vec + catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec # epfl-made \n",
    "sent2vec_model = sent2vec.Sent2vecModel()\n",
    "sent2vec_model.load_model('../data/pretrained_models/wiki_unigrams.bin') # 600 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2897,), (1242,))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(df, test_size=0.3) # random_state = 0\n",
    "\n",
    "X_train = data_train['title']\n",
    "y_train = data_train['labels']\n",
    "\n",
    "X_test = data_test['title']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = model.embed_sentence(X_train.values[0])\n",
    "X_train_embs = sent2vec_model.embed_sentences(X_train.values)\n",
    "X_test_embs  = sent2vec_model.embed_sentences(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2897, numpy.ndarray, 600, numpy.float32)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_embs), type(X_train_embs[0]), len(X_train_embs[0]), type(X_train_embs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# okay, now we have 600-dim vectors for every sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6926772\ttotal: 444ms\tremaining: 8.44s\n",
      "1:\tlearn: 0.6921521\ttotal: 809ms\tremaining: 7.28s\n",
      "2:\tlearn: 0.6917532\ttotal: 1.16s\tremaining: 6.59s\n",
      "3:\tlearn: 0.6911088\ttotal: 1.5s\tremaining: 5.99s\n",
      "4:\tlearn: 0.6905577\ttotal: 1.84s\tremaining: 5.53s\n",
      "5:\tlearn: 0.6899111\ttotal: 2.19s\tremaining: 5.11s\n",
      "6:\tlearn: 0.6891931\ttotal: 2.54s\tremaining: 4.71s\n",
      "7:\tlearn: 0.6886826\ttotal: 2.87s\tremaining: 4.3s\n",
      "8:\tlearn: 0.6880764\ttotal: 3.21s\tremaining: 3.92s\n",
      "9:\tlearn: 0.6875701\ttotal: 3.57s\tremaining: 3.57s\n",
      "10:\tlearn: 0.6870024\ttotal: 3.92s\tremaining: 3.21s\n",
      "11:\tlearn: 0.6865093\ttotal: 4.27s\tremaining: 2.85s\n",
      "12:\tlearn: 0.6859601\ttotal: 4.64s\tremaining: 2.5s\n",
      "13:\tlearn: 0.6853783\ttotal: 5.01s\tremaining: 2.15s\n",
      "14:\tlearn: 0.6850455\ttotal: 5.36s\tremaining: 1.79s\n",
      "15:\tlearn: 0.6846253\ttotal: 5.72s\tremaining: 1.43s\n",
      "16:\tlearn: 0.6842575\ttotal: 6.04s\tremaining: 1.07s\n",
      "17:\tlearn: 0.6837380\ttotal: 6.41s\tremaining: 712ms\n",
      "18:\tlearn: 0.6831759\ttotal: 6.77s\tremaining: 356ms\n",
      "19:\tlearn: 0.6826389\ttotal: 7.13s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5797101449275363"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=20, learning_rate=1e-2, depth=6, loss_function='Logloss')\n",
    "model.fit(X_train_embs, y_train)\n",
    "preds_class = model.predict(X_test_embs)\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6886654\ttotal: 335ms\tremaining: 6.37s\n",
      "1:\tlearn: 0.6839143\ttotal: 727ms\tremaining: 6.54s\n",
      "2:\tlearn: 0.6789297\ttotal: 1.09s\tremaining: 6.2s\n",
      "3:\tlearn: 0.6733863\ttotal: 1.45s\tremaining: 5.82s\n",
      "4:\tlearn: 0.6684119\ttotal: 1.86s\tremaining: 5.58s\n",
      "5:\tlearn: 0.6638178\ttotal: 2.24s\tremaining: 5.23s\n",
      "6:\tlearn: 0.6597300\ttotal: 2.64s\tremaining: 4.91s\n",
      "7:\tlearn: 0.6559614\ttotal: 3.01s\tremaining: 4.52s\n",
      "8:\tlearn: 0.6530037\ttotal: 3.35s\tremaining: 4.1s\n",
      "9:\tlearn: 0.6492160\ttotal: 3.72s\tremaining: 3.72s\n",
      "10:\tlearn: 0.6460629\ttotal: 4.07s\tremaining: 3.33s\n",
      "11:\tlearn: 0.6431014\ttotal: 4.44s\tremaining: 2.96s\n",
      "12:\tlearn: 0.6399529\ttotal: 4.77s\tremaining: 2.57s\n",
      "13:\tlearn: 0.6368744\ttotal: 5.13s\tremaining: 2.2s\n",
      "14:\tlearn: 0.6348356\ttotal: 5.45s\tremaining: 1.81s\n",
      "15:\tlearn: 0.6324356\ttotal: 5.8s\tremaining: 1.45s\n",
      "16:\tlearn: 0.6310915\ttotal: 6.14s\tremaining: 1.08s\n",
      "17:\tlearn: 0.6288093\ttotal: 6.49s\tremaining: 722ms\n",
      "18:\tlearn: 0.6263107\ttotal: 6.84s\tremaining: 360ms\n",
      "19:\tlearn: 0.6227640\ttotal: 7.21s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.605475040257649"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=20, learning_rate=1e-1, depth=6, loss_function='Logloss')\n",
    "model.fit(X_train_embs, y_train)\n",
    "preds_class = model.predict(X_test_embs)\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6694659\ttotal: 333ms\tremaining: 6.33s\n",
      "1:\tlearn: 0.6557130\ttotal: 686ms\tremaining: 6.17s\n",
      "2:\tlearn: 0.6433759\ttotal: 1.01s\tremaining: 5.75s\n",
      "3:\tlearn: 0.6240297\ttotal: 1.4s\tremaining: 5.6s\n",
      "4:\tlearn: 0.6161339\ttotal: 1.72s\tremaining: 5.16s\n",
      "5:\tlearn: 0.6058691\ttotal: 2.11s\tremaining: 4.92s\n",
      "6:\tlearn: 0.5933744\ttotal: 2.51s\tremaining: 4.66s\n",
      "7:\tlearn: 0.5853006\ttotal: 2.96s\tremaining: 4.45s\n",
      "8:\tlearn: 0.5708500\ttotal: 3.41s\tremaining: 4.17s\n",
      "9:\tlearn: 0.5587854\ttotal: 3.82s\tremaining: 3.82s\n",
      "10:\tlearn: 0.5494930\ttotal: 4.18s\tremaining: 3.42s\n",
      "11:\tlearn: 0.5320407\ttotal: 4.55s\tremaining: 3.03s\n",
      "12:\tlearn: 0.5228499\ttotal: 4.88s\tremaining: 2.63s\n",
      "13:\tlearn: 0.5072924\ttotal: 5.23s\tremaining: 2.24s\n",
      "14:\tlearn: 0.4919035\ttotal: 5.58s\tremaining: 1.86s\n",
      "15:\tlearn: 0.4764114\ttotal: 5.95s\tremaining: 1.49s\n",
      "16:\tlearn: 0.4626371\ttotal: 6.31s\tremaining: 1.11s\n",
      "17:\tlearn: 0.4515207\ttotal: 6.67s\tremaining: 742ms\n",
      "18:\tlearn: 0.4397122\ttotal: 7.01s\tremaining: 369ms\n",
      "19:\tlearn: 0.4383143\ttotal: 7.33s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6111111111111112"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=20, learning_rate=1, depth=6, loss_function='Logloss')\n",
    "model.fit(X_train_embs, y_train)\n",
    "preds_class = model.predict(X_test_embs)\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n",
      "learning rate is greater than 1. You probably need to decrease learning rate.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.3848086\ttotal: 346ms\tremaining: 6.57s\n",
      "1:\tlearn: 24.3764645\ttotal: 703ms\tremaining: 6.33s\n",
      "2:\tlearn: 251.7797294\ttotal: 1.06s\tremaining: 6.01s\n",
      "3:\tlearn: nan\ttotal: 1.08s\tremaining: 4.31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training has stopped (degenerate solution on iteration 3, probably too small l2-regularization, try to increase it)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5257648953301127"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CatBoostClassifier(iterations=20, learning_rate=10, depth=6, loss_function='Logloss')\n",
    "model.fit(X_train_embs, y_train)\n",
    "preds_class = model.predict(X_test_embs)\n",
    "np.mean(preds_class == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
