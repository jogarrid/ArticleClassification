{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from scraper_WoS import WosClient\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soap = WosClient(lite=True)\n",
    "soap.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the names \n",
    "searchnames = []\n",
    "i=0\n",
    "for line in open('../Data/Dismiss_Acad_List.txt','r'):\n",
    "    QueryString = line.strip()\n",
    "    QueryString = \"AU=\"+line.split(',')[0].split()[-1]+' '+line.split(',')[0].split()[0]\n",
    "    print('QueryString:', QueryString)\n",
    "    searchnames.append(QueryString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(searchnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(searchnames)\n",
    "pd.DataFrame(searchnames,columns=['SearchNames']).to_csv('SearchNames.csv')\n",
    "#save Search names in csv file\n",
    "SearchNames = pd.read_csv('SearchNames.csv')\n",
    "SearchNames.SearchNames[0].strip().split('=')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soap = WosClient(lite=True)\n",
    "soap.connect()\n",
    "#query = \"VA= Article\"\n",
    "res=soap.search(QueryString)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "lens = []\n",
    "co_aut = []\n",
    "i=0\n",
    "for i in range(len(SearchNames)):\n",
    "    line = SearchNames.SearchNames[i]\n",
    "    QueryString = line\n",
    "    print(QueryString)\n",
    "    if i == 2400: # WOS constraints that each ID can only search for 2500 times. Just set smaller counts to renew the ID.\n",
    "        soap = WosClient(lite=True)\n",
    "        soap.connect()\n",
    "    results = soap.search(QueryString)\n",
    "    #getting number of name of co-authors\n",
    "    if (results.recordsFound>0):\n",
    "        authors = []\n",
    "        for j in range (len(results.records)):\n",
    "            for k in range (len(results.records[j].authors)):\n",
    "                for l in range (len(results.records[j].authors[k].value)):\n",
    "                    co_authors=results.records[j].authors[k].value[l]\n",
    "                    authors.append(co_authors)\n",
    "                    print('co_author',co_authors)\n",
    "                #co_aut.append(authors)\n",
    "            #co.append(co_aut)\n",
    "    print(results.recordsFound)\n",
    "    names.append(QueryString.split('=')[1])\n",
    "    lens.append(results.recordsFound)\n",
    "    co_aut.append(authors)\n",
    "    time.sleep(0.5) # WOS constraints that you can only search twice per second\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a python module to make unicode strings work as expected for turkish chars. solves the turkish \"Ä°\" problem\n",
    "\n",
    "# have to do pip install unicode_tr\n",
    "names_en = []\n",
    "from unicode_tr.extras import slugify\n",
    "for i in range(len(names)):\n",
    "    name_en = slugify(names[i])\n",
    "    name_en = name_en.replace('-',' ').title()\n",
    "    names_en.append(name_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([name,lens,co_aut]).T\n",
    "df.columns=['Author','NoPapers','CoAuthors']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting co authors column to match with authors\n",
    "#for i in range(df.shape[0]):\n",
    "#    for j in range(len(df.CoAuthors.iloc[i])):\n",
    "#        a=df.CoAuthors.iloc[i]\n",
    "#        a[j]=a[j].replace(\",\",\" \")\n",
    "#        df.CoAuthors.iloc[i] = a\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt=0\n",
    "for l in co_aut:\n",
    "    cnt += len(l)\n",
    "print('Totally ' + str(cnt) + ' guys were downloaded as coauthors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coauthors = set()\n",
    "for l in co_aut:\n",
    "    for author in l:\n",
    "        author = author.replace(',', '')\n",
    "        coauthors.add(author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's now create the file with not-dismissed professors:\n",
    "dismissed = set(names_en)\n",
    "\n",
    "print('Totally we have ' + str(len(dismissed)) + ' dismissed and ' + str(len(coauthors)) + ' unique coauthors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undismissed = coauthors - dismissed\n",
    "print('So, we have ' + str(len(undismissed)) + ' undismissed guys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dismissed_df = pd.DataFrame()\n",
    "dismissed_df['AU']=list(dismissed)\n",
    "dismissed_df.to_csv('../data/dismissed.csv')\n",
    "undismissed_df = pd.DataFrame()\n",
    "undismissed_df['AU']=list(undismissed)\n",
    "undismissed_df.to_csv('../data/undismissed.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
